{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "\n",
    "from contextlib import closing\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = mp.get_logger().info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imsave\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from skimage import img_as_float\n",
    "import multiprocess as mp\n",
    "import cv2\n",
    "\n",
    "def process_images(image_paths_list):\n",
    "    \n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    images = Parallel(n_jobs=6, verbose=5)(\n",
    "        delayed(Image.open)(f) for f in image_paths_list\n",
    "    )   \n",
    "\n",
    "    new_images = []\n",
    "    def resize_process(task_info):\n",
    "        im = task_info\n",
    "        im_resized = im.resize((224, 224), Image.ANTIALIAS) \n",
    "        im_arr = np.expand_dims(im_resized, axis=0) # add one dimension as 1\n",
    "        im_arr.flags.writeable = True\n",
    "        im_arr = im_arr.astype(np.float64)\n",
    "        return im_arr\n",
    "    \n",
    "    def resize_organizer():\n",
    "        task_list = []\n",
    "        for im in images:\n",
    "            task_list.append(im)\n",
    "        p = mp.Pool(mp.cpu_count())\n",
    "        new_images = p.map(resize_process, task_list)\n",
    "        return new_images\n",
    "\n",
    "#     images = Parallel(n_jobs=6, verbose=5)(\n",
    "#         delayed(img_as_float)(f) for f in images\n",
    "#     )\n",
    "    \n",
    "#     task_list2 = []\n",
    "#     features = []\n",
    "#     def predict_process(task_info):\n",
    "#         im = task_info\n",
    "#         features.append(model.predict(im))\n",
    "        \n",
    "#     p = mp.Pool(mp.cpu_count())\n",
    "#     features = p.map(predict_process(), images)\n",
    "    new_images = resize_organizer()\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sunjiajun/cs231n_project/datasets/frames/video0/frame1.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame2.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame3.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame4.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame5.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame6.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame7.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame8.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame9.jpg',\n",
       " '/home/sunjiajun/cs231n_project/datasets/frames/video0/frame10.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths_list = []\n",
    "for i in range(1000):\n",
    "    path = os.getcwd() + '/datasets/frames/video' + str(i)\n",
    "    if not os.path.exists(path): continue\n",
    "    image_paths_list.extend([path + \\\n",
    "                             '/frame' +str(idx)+'.jpg' for idx in range(1, 11, 1)])\n",
    "image_paths_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "[joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1e666f2384cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-e03fed364593>\u001b[0m in \u001b[0;36mprocess_images\u001b[1;34m(image_paths_list)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     images = Parallel(n_jobs=6, verbose=5)(\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage_paths_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     )   \n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             return self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[1;32m--> 540\u001b[1;33m                                            **self._backend_args)\n\u001b[0m\u001b[0;32m    541\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFallbackToBackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;31m# Recursively initialize the backend in case of requested fallback.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[1;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             raise ImportError(\n\u001b[1;32m--> 299\u001b[1;33m                 \u001b[1;34m'[joblib] Attempting to do parallel computing '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;34m'without protecting your import on a system that does '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[1;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: [joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
     ]
    }
   ],
   "source": [
    "im = process_images(image_paths_list[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
