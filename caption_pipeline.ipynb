{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# !/usr/env python3\n",
    "\n",
    "'''\n",
    "Output:\n",
    "video captioning model itself and produce loss curve\n",
    "\n",
    "Usage:\n",
    "main document to train the video captioning model\n",
    "'''\n",
    "\n",
    "# set up\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from model.video_caption import sequence_2_sequence_LSTM\n",
    "from load_caption_feature import *\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and save data  \n",
    "Load caption Xtrain, Xtest, ytrain, ytest, video_train, video_test and save them.  \n",
    "Here in details, see **load_caption_feature.py**. Only need to run once, codes are going to save the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing videos...\n",
      "process 70/4270\n",
      "process 140/4270\n",
      "process 210/4270\n",
      "process 280/4270\n",
      "process 350/4270\n",
      "process 420/4270\n",
      "process 490/4270\n",
      "process 560/4270\n",
      "process 630/4270\n",
      "process 700/4270\n",
      "process 770/4270\n",
      "process 840/4270\n",
      "process 910/4270\n",
      "process 980/4270\n",
      "process 1050/4270\n",
      "process 1120/4270\n",
      "process 1190/4270\n",
      "process 1260/4270\n",
      "process 1330/4270\n",
      "process 1400/4270\n",
      "process 1470/4270\n",
      "process 1540/4270\n",
      "process 1610/4270\n",
      "process 1680/4270\n",
      "process 1750/4270\n",
      "process 1820/4270\n",
      "process 1890/4270\n",
      "process 1960/4270\n",
      "process 2030/4270\n",
      "process 2100/4270\n",
      "process 2170/4270\n",
      "process 2240/4270\n",
      "process 2310/4270\n",
      "process 2380/4270\n",
      "process 2450/4270\n",
      "process 2520/4270\n",
      "process 2590/4270\n",
      "process 2660/4270\n",
      "process 2730/4270\n",
      "process 2800/4270\n",
      "process 2870/4270\n",
      "process 2940/4270\n",
      "process 3010/4270\n",
      "process 3080/4270\n",
      "process 3150/4270\n",
      "process 3220/4270\n",
      "process 3290/4270\n",
      "process 3360/4270\n",
      "process 3430/4270\n",
      "process 3500/4270\n",
      "process 3570/4270\n",
      "process 3640/4270\n",
      "process 3710/4270\n",
      "process 3780/4270\n",
      "process 3850/4270\n",
      "process 3920/4270\n",
      "process 3990/4270\n",
      "process 4060/4270\n",
      "process 4130/4270\n",
      "process 4200/4270\n",
      "process 4270/4270\n",
      "cache processed data...\n"
     ]
    }
   ],
   "source": [
    "# load and save training data\n",
    "num_frames = 15\n",
    "size = (224, 224, 3)\n",
    "\n",
    "# more balanced data\n",
    "idx_path = os.getcwd() + '/datasets/x_train_ind_above400.npy'\n",
    "Xtrain_idx = np.load(idx_path)\n",
    "labels = np.load(os.getcwd() + '/datasets/y_train_mapped_above400.npy')\n",
    "\n",
    "# if all videos then \n",
    "num_videos = len(Xtrain_idx)\n",
    "\n",
    "tic = datetime.now()\n",
    "# for clearing memory convenience\n",
    "model = vgg_16_pretrained()\n",
    "Xtr, ytr = load_features(model, num_videos, num_frames, Xtrain_idx, labels, size = (224, 224, 3), train_test_flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear memory\n",
    "del Xtr\n",
    "del ytr\n",
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing videos...\n",
      "process 30/1830\n",
      "process 60/1830\n",
      "process 90/1830\n",
      "process 120/1830\n",
      "process 150/1830\n",
      "process 180/1830\n",
      "process 210/1830\n",
      "process 240/1830\n",
      "process 270/1830\n",
      "process 300/1830\n",
      "process 330/1830\n",
      "process 360/1830\n",
      "process 390/1830\n",
      "process 420/1830\n",
      "process 450/1830\n",
      "process 480/1830\n",
      "process 510/1830\n",
      "process 540/1830\n",
      "process 570/1830\n",
      "process 600/1830\n",
      "process 630/1830\n",
      "process 660/1830\n",
      "process 690/1830\n",
      "process 720/1830\n",
      "process 750/1830\n",
      "process 780/1830\n",
      "process 810/1830\n",
      "process 840/1830\n",
      "process 870/1830\n",
      "process 900/1830\n",
      "process 930/1830\n",
      "process 960/1830\n",
      "process 990/1830\n",
      "process 1020/1830\n",
      "process 1050/1830\n",
      "process 1080/1830\n",
      "process 1110/1830\n",
      "process 1140/1830\n",
      "process 1170/1830\n",
      "process 1200/1830\n",
      "process 1230/1830\n",
      "process 1260/1830\n",
      "process 1290/1830\n",
      "process 1320/1830\n",
      "process 1350/1830\n",
      "process 1380/1830\n",
      "process 1410/1830\n",
      "process 1440/1830\n",
      "process 1470/1830\n",
      "process 1500/1830\n",
      "process 1530/1830\n",
      "process 1560/1830\n",
      "process 1590/1830\n",
      "process 1620/1830\n",
      "process 1650/1830\n",
      "process 1680/1830\n",
      "process 1710/1830\n",
      "process 1740/1830\n",
      "process 1770/1830\n",
      "process 1800/1830\n",
      "process 1830/1830\n",
      "cache processed data...\n"
     ]
    }
   ],
   "source": [
    "# load and save test data\n",
    "num_frames_test = 15\n",
    "size = (224, 224, 3)\n",
    "\n",
    "# more balanced data\n",
    "idx_path = os.getcwd() + '/datasets/x_test_ind_above400.npy'\n",
    "Xtest_idx = np.load(idx_path)\n",
    "ytest = np.load(os.getcwd() + '/datasets/y_test_mapped_above400.npy')\n",
    "\n",
    "# if all videos then \n",
    "num_videos_test = len(Xtest_idx)\n",
    "\n",
    "model = vgg_16_pretrained()\n",
    "Xte, yte = load_features(model, num_videos_test, num_frames_test, Xtest_idx, ytest, size = (224, 224, 3), train_test_flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean memory\n",
    "del Xte\n",
    "del yte\n",
    "model = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save input frames train and test\n",
    "curr = os.getcwd() + '/datasets'\n",
    "def save_frames(X, vid_ls, mode = 'train'):\n",
    "    X = X.reshape((-1, 15, 4096))\n",
    "    assert X.shape[0] == len(vid_ls)\n",
    "    input_frames = {}\n",
    "    for i in range(X.shape[0]):\n",
    "        vid = vid_ls[i]\n",
    "        input_frames[vid] = Xtr[i]\n",
    "    pickle.dump(input_frames, open(curr + '/input_frames_' + mode + '.pickle', 'wb'))\n",
    "\n",
    "vid_train = np.load(curr + '/videoIdtrain_allCap_15frames.npy')\n",
    "Xtr = np.load(curr + '/Xtrain_allCap_15frames.npy')\n",
    "Xte = np.load(curr + '/Xtest_allCap_15frames.npy')\n",
    "vid_test = np.load(curr + '/videoIdtest_allCap_15frames.npy')\n",
    "save_frames(Xtr, vid_train, mode = 'train')\n",
    "save_frames(Xte, vid_test, mode = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration and Parameters \n",
    "Parameters:  \n",
    "\n",
    "* model_name: the name of model, here we refer sequence to sequence model from [1](https://arxiv.org/abs/1505.00487);  \n",
    "* state_size: lstm encoder and encoder state dimension  \n",
    "* learning_rate: learning rate  \n",
    "* input_size: vector size input to lstm, here we use pretrained VGG16 output 4096 dimension  \n",
    "* batch_size: batch size  \n",
    "* max_sentence_length: fixed length for captions, default is 20 \n",
    "* word_vector_size: depends on vocabulary chosen, here is 50, but can be changed \n",
    "* voc_size: depends on vocabulary created, if self-created vocabulary, it is 6169, if glove\n",
    "* n_epoches: the number of epoches to run  \n",
    "* num_frames: frame number  \n",
    "* hidden_size: lstm encoder and encoder hidden dimension \n",
    "\n",
    "**Reference**  \n",
    "[1] Venugopalan, S., Rohrbach, M., Donahue, J., Mooney, R., Darrell, T., & Saenko, K. (2015). Sequence to sequence-video to text. In Proceedings of the IEEE International Conference on Computer Vision (pp. 4534-4542).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "lr = 1e-1\n",
    "hidden_size = 1000\n",
    "state_size = 100\n",
    "batch_size = 64\n",
    "voc_size = 6169\n",
    "epoch = 100\n",
    "word_dim = 50\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "#=======Change These===============================\n",
    "tf.app.flags.DEFINE_string(\"model_name\", \"sequence2sequence\", \"name of the model\")\n",
    "tf.app.flags.DEFINE_integer(\"state_size\", state_size, \"Size of each model layer.\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", lr, \"Base Learning rate.\")\n",
    "#==================================================\n",
    "\n",
    "tf.app.flags.DEFINE_float(\"input_size\", 4096, \"input size for each frame\")\n",
    "tf.app.flags.DEFINE_integer(\"batch_size\", batch_size, \"how many videos put per run\")\n",
    "tf.app.flags.DEFINE_integer(\"max_sentence_length\", 20, \"maximum captioning sentence length\")\n",
    "tf.app.flags.DEFINE_integer(\"word_vector_size\", word_dim, \"word embedding dimension default is 25 for twitter glove\")\n",
    "tf.app.flags.DEFINE_integer(\"voc_size\", voc_size, \"vocabulary size\")\n",
    "tf.app.flags.DEFINE_integer(\"n_epochs\", epoch, \"number of epoch to run\")\n",
    "tf.app.flags.DEFINE_integer(\"num_frames\", 15, \"number of frames per video\")\n",
    "tf.app.flags.DEFINE_integer(\"hidden_size\", hidden_size, \"output size of LSTM encoder and decoder\")\n",
    "FLAGS = tf.app.flags.FLAGS        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading training data!\n"
     ]
    }
   ],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "curPath = os.getcwd()\n",
    "dataPath = curPath + \"/datasets/\"\n",
    "\n",
    "# pick first 100 for debugging purpose\n",
    "# load data\n",
    "sample_size = 4270\n",
    "wvector_dim = 50\n",
    "is_training = True\n",
    "input_frames_train, captions_train, \\\n",
    "        word_dict, word2Index, index2Word = load_caption_data(sample_size, dataPath, train = is_training)\n",
    "word_embedding = word_embedding_array(word_dict, wvector_dim, word2Index) \n",
    "print('Finish loading training data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model Graph  \n",
    "In details, see **model/video_caption.py**.   \n",
    "We refer to sequence to sequence model to build two LSTM layers. One is encoder, and the other is decoder. The cell number of decoder depends on the maximum caption length we set. Here we choose 20 here by exploring the distribution of captions. In order to make encoder have same length of outputs, we add pad cells to encoder. Encoder accept 15 frames VGG16 outputs so that it has 15 cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start building model ...\n",
      "zt shape:  (?, 50)\n",
      "embedding shape:  (6169, 50)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d422ae91a850>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence_2_sequence_LSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'start building model ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_embedding_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_prediction_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_training_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36madd_prediction_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m                                         training = self.is_training_placeholder)\n\u001b[0;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_ind\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_loss_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1574\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m             use_resource=use_resource) as vs:\n\u001b[1;32m-> 1576\u001b[1;33m           \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[1;34m(self, default)\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[1;34m(self, default)\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2858\u001b[0m         \u001b[0mnew_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2859\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2860\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnew_stack\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnew_stack\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2861\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2862\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_pure_variable_scope\u001b[1;34m(name_or_scope, reuse, initializer, regularizer, caching_device, partitioner, custom_getter, old_name_scope, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1362\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mdefault_varscope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault_varscope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[0mvar_store\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_variable_subscopes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36madd_prediction_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    209\u001b[0m                                         \u001b[0mmax_sentence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                                         \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_placeholder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                                         training = self.is_training_placeholder)\n\u001b[0m\u001b[0;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_ind\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mdecoder\u001b[1;34m(encoder_state, encoder_outputs, input_caption, word_vector_size, embedding, pretrained_embedding, voc_size, hidden_size, max_sentence_length, dropout, training)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1574\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m             use_resource=use_resource) as vs:\n\u001b[1;32m-> 1576\u001b[1;33m           \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[1;34m(self, default)\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[1;34m(self, default)\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2858\u001b[0m         \u001b[0mnew_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2859\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2860\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnew_stack\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnew_stack\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2861\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2862\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4167\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m \u001b[1;31m# pylint: enable=g-doc-return-or-yield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't stop after throw()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_pure_variable_scope\u001b[1;34m(name_or_scope, reuse, initializer, regularizer, caching_device, partitioner, custom_getter, old_name_scope, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1362\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mdefault_varscope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mdefault_varscope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[0mvar_store\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_variable_subscopes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mvariable_scope\u001b[1;34m(name_or_scope, default_name, values, initializer, regularizer, caching_device, partitioner, custom_getter, reuse, dtype, use_resource)\u001b[0m\n\u001b[0;32m   1545\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m               use_resource=use_resource) as vs:\n\u001b[1;32m-> 1547\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;31m# This can only happen if someone is entering the root variable scope.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mdecoder\u001b[1;34m(encoder_state, encoder_outputs, input_caption, word_vector_size, embedding, pretrained_embedding, voc_size, hidden_size, max_sentence_length, dropout, training)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zt shape: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'embedding shape: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# build model graph\n",
    "tf.reset_default_graph()\n",
    "model = sequence_2_sequence_LSTM(word_embedding, FLAGS)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'LSTM_seq2seq/encoder/basic_lstm_cell/weights:0' shape=(5096, 4000) dtype=float32_ref>\n",
      "<tf.Variable 'LSTM_seq2seq/encoder/basic_lstm_cell/biases:0' shape=(4000,) dtype=float32_ref>\n",
      "<tf.Variable 'LSTM_seq2seq/decoder/basic_lstm_cell/weights:0' shape=(2050, 4000) dtype=float32_ref>\n",
      "<tf.Variable 'LSTM_seq2seq/decoder/basic_lstm_cell/biases:0' shape=(4000,) dtype=float32_ref>\n",
      "<tf.Variable 'LSTM_seq2seq/decoder/hidden_to_scores/kernel:0' shape=(1000, 50) dtype=float32_ref>\n",
      "<tf.Variable 'LSTM_seq2seq/decoder/hidden_to_scores/bias:0' shape=(50,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# check variables\n",
    "for v in tf.trainable_variables():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 1280 values, but the requested shape has 123380\n\t [[Node: loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](loss/Cast, loss/Reshape_1/shape)]]\n\t [[Node: LSTM_seq2seq/decoder/ArgMax_5/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_11217_LSTM_seq2seq/decoder/ArgMax_5\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'loss/Reshape_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-d422ae91a850>\", line 4, in <module>\n    model.build()\n  File \"/home/sunjiajun/cs231n_project/model/video_caption.py\", line 112, in build\n    self.loss = self.add_loss_op(self.pred)\n  File \"/home/sunjiajun/cs231n_project/model/video_caption.py\", line 229, in add_loss_op\n    captions_flat = tf.cast(tf.reshape(captions, [N*T,]), tf.int32)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2510, in reshape\n    name=name)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1280 values, but the requested shape has 123380\n\t [[Node: loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](loss/Cast, loss/Reshape_1/shape)]]\n\t [[Node: LSTM_seq2seq/decoder/ArgMax_5/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_11217_LSTM_seq2seq/decoder/ArgMax_5\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1280 values, but the requested shape has 123380\n\t [[Node: loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](loss/Cast, loss/Reshape_1/shape)]]\n\t [[Node: LSTM_seq2seq/decoder/ArgMax_5/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_11217_LSTM_seq2seq/decoder/ArgMax_5\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-65a677805f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_frames_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sess, train_data, verbose)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mprog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mdev_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m                 \u001b[1;31m# print epoch results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(self, sess, train_data, valid_data, verbose)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mvid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/model/video_caption.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, sess, input_frames, input_caption)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                      \u001b[0minput_caption\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_caption\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                                      is_training=True)\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1280 values, but the requested shape has 123380\n\t [[Node: loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](loss/Cast, loss/Reshape_1/shape)]]\n\t [[Node: LSTM_seq2seq/decoder/ArgMax_5/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_11217_LSTM_seq2seq/decoder/ArgMax_5\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'loss/Reshape_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-d422ae91a850>\", line 4, in <module>\n    model.build()\n  File \"/home/sunjiajun/cs231n_project/model/video_caption.py\", line 112, in build\n    self.loss = self.add_loss_op(self.pred)\n  File \"/home/sunjiajun/cs231n_project/model/video_caption.py\", line 229, in add_loss_op\n    captions_flat = tf.cast(tf.reshape(captions, [N*T,]), tf.int32)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2510, in reshape\n    name=name)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sunjiajun/cs231n_project/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1280 values, but the requested shape has 123380\n\t [[Node: loss/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](loss/Cast, loss/Reshape_1/shape)]]\n\t [[Node: LSTM_seq2seq/decoder/ArgMax_5/_33 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_11217_LSTM_seq2seq/decoder/ArgMax_5\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# run training mode\n",
    "with get_session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out = model.train(sess, (input_frames_train, captions_train), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unpack\n",
    "val_loss, tr_loss, tr_pred, val_pred, train_vid, val_vid = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEbCAYAAAAyIYQrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ff37bd278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve\n",
    "plt.plot(range(len(tr_loss)), tr_loss, 'r-', linewidth = 2, label = 'train')\n",
    "plt.plot(range(len(val_loss)), val_loss, 'b-', linewidth = 2, label = 'validation')\n",
    "plt.grid()\n",
    "plt.xlabel('iteration', fontsize = 13)\n",
    "plt.ylabel('loss', fontsize = 13)\n",
    "plt.title('iteration vs loss', fontsize = 15)\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + '/output/caption_learning_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check batch captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Caption:  a a a a a a a\n",
      "True Caption:  drawn cry prepared with roasted pawns red child and gram nasal south indian style\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a\n",
      "True Caption:  one man and women talking something in a public\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a\n",
      "True Caption:  a cartoon character is jumping up a ledge\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a a\n",
      "True Caption:  a man in a winter coat stand front of lights\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a a a a\n",
      "True Caption:  a man is kissing a woman while a woman and a baby laugh\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a the a a a\n",
      "True Caption:  it is a collection of classic film quotes including james bond saying his name and the godfather says\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a\n",
      "True Caption:  a young girl showing how to make cake bump\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a the\n",
      "True Caption:  a young girl dressed in pink and black plays tennis\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a\n",
      "True Caption:  a person is dancing in the elevator\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a\n",
      "True Caption:  a small boy crying while a star flies around him\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a a\n",
      "True Caption:  man in blue shirt is hitting the ball and scoring a point\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a\n",
      "True Caption:  a man is blow up and british soldiers carry a person away\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a\n",
      "True Caption:  someone is watching shows\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a a a a\n",
      "True Caption:  a brown color horse holding belt a white color dress lady speaking displaying on screen\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a\n",
      "True Caption:  someone folding a paper\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a the\n",
      "True Caption:  there is a man is walking with a gun\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a a\n",
      "True Caption:  two asia women having a conversation with the dialogue closed cautioned on the bottom\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a the a a\n",
      "True Caption:  a red car is sitting in the parking lot and a person is hold some keys\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a\n",
      "True Caption:  picture of an orange sports car\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a\n",
      "True Caption:  a person playing a leg game\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a\n",
      "True Caption:  a man preparing drill chicken and explaining about it\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a a\n",
      "True Caption:  a man and a woman or sitting on the couch talking\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a a a a\n",
      "True Caption:  a kid plays with dinosaur toys and eggs wearing jurassic world white shirt\n",
      "--------------------------------------------------\n",
      "Pred Caption:  a a a a a\n",
      "True Caption:  a girl is telling something to people\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check captions\n",
    "batch_size = 24\n",
    "# sample = tr_pred[idx] # training\n",
    "# # sample = val_pred[idx] # validation \n",
    "# words = []\n",
    "# embed_train = False # whether train embedding word\n",
    "\n",
    "captions = {k: v for k, v in captions_train}\n",
    "# caption check\n",
    "for j in range(batch_size):\n",
    "    words = []\n",
    "    trues = []\n",
    "    sample = tr_pred[j]\n",
    "    vid = train_vid[j]\n",
    "    cap = captions[vid]\n",
    "    for idx, i in enumerate(sample):\n",
    "        word = index2Word[i]\n",
    "        true = index2Word[cap[idx]]\n",
    "        if word not in ['<START>', '<END>', '<pad>']:\n",
    "            words.append(word)\n",
    "        if true not in ['<START>', '<END>', '<pad>']:\n",
    "            trues.append(true)   \n",
    "    print('Pred Caption: ', ' '.join(w for w in words))\n",
    "    print('True Caption: ', ' '.join(t for t in trues))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
